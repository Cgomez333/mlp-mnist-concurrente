# MLP MNIST Concurrente

ImplementaciÃ³n y paralelizaciÃ³n de una Red Neuronal MLP desde cero para clasificaciÃ³n de dÃ­gitos MNIST.

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un **PerceptrÃ³n Multicapa (MLP)** desde cero en diferentes paradigmas de programaciÃ³n para comparar su rendimiento:

- **Python Secuencial**: ImplementaciÃ³n baseline con NumPy
- **Python Multiprocessing**: ParalelizaciÃ³n con procesos
- **C Secuencial**: ImplementaciÃ³n optimizada en C
- **C + OpenMP**: ParalelizaciÃ³n con memoria compartida
- **PyCUDA**: AceleraciÃ³n en GPU

**Objetivo**: Analizar cuellos de botella computacionales y medir Speedup, Overhead y Ley de Amdahl.

## ğŸ¯ Especificaciones

### Arquitectura MLP (Fija)

- **Entrada**: 784 neuronas (28Ã—28 pÃ­xeles)
- **Capa Oculta**: 512 neuronas (ReLU)
- **Salida**: 10 neuronas (Softmax)
- **Loss**: Cross-Entropy

### HiperparÃ¡metros

```python
EPOCHS = 10
LEARNING_RATE = 0.01
BATCH_SIZE = 64  # CPU implementations
RANDOM_SEED = 42
```

## ğŸ“ Estructura del Proyecto

```
mlp-mnist-concurrente/
â”œâ”€â”€ README.md
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ experiment_design.md          # DocumentaciÃ³n completa
â”œâ”€â”€ data/
â”‚   â””â”€â”€ mnist/                        # Dataset MNIST
â”œâ”€â”€ python_secuencial/                # ImplementaciÃ³n Python base
â”œâ”€â”€ python_multiprocessing/           # Python paralelo
â”œâ”€â”€ pycuda_gpu/                       # ImplementaciÃ³n GPU
â”œâ”€â”€ c_secuencial/                     # ImplementaciÃ³n C base
â”œâ”€â”€ c_openmp/                         # C con OpenMP
â”œâ”€â”€ scripts/                          # Scripts de anÃ¡lisis
â””â”€â”€ results/                          # Resultados y grÃ¡ficas
    â”œâ”€â”€ raw/                          # CSVs con mÃ©tricas
    â”‚   â””â”€â”€ weights/                  # Pesos finales
    â””â”€â”€ figures/                      # GrÃ¡ficas comparativas
```

## ğŸš€ Inicio RÃ¡pido

### Requisitos

**Python**:

```bash
pip install numpy matplotlib
pip install pycuda  # Solo para versiÃ³n GPU
```

**C/C++**:

```bash
gcc --version  # GCC con soporte OpenMP
```

### Descarga del Dataset

```bash
cd scripts
python download_mnist.py
python preprocess_data.py  # Genera archivos .bin para C
```

## ğŸ”§ EjecuciÃ³n

### Python Secuencial

```bash
cd python_secuencial
python train.py
```

### Python Multiprocessing

```bash
cd python_multiprocessing
python train_parallel.py --processes 4
```

### C Secuencial

**Primero instala GCC** (ver `docs/INSTALL_C_TOOLS.md`):

```bash
cd c_secuencial

# OpciÃ³n 1: Con Make (si tienes MinGW/MSYS2)
make

# OpciÃ³n 2: Script de Windows
compile.bat

# Ejecutar
./bin/train_seq.exe  # Windows
./bin/train_seq      # Linux/Mac
```

### C + OpenMP

```bash
cd c_openmp

# Compilar
make
# o
compile.bat

# Ejecutar con diferentes hilos
set OMP_NUM_THREADS=1 && ./bin/train_omp.exe  # Windows
export OMP_NUM_THREADS=8 && ./bin/train_omp   # Linux/Mac
```

### PyCUDA (en Colab)

```bash
# Ver notebooks/pycuda_experiments.ipynb
```

## ğŸ“Š AnÃ¡lisis de Resultados

```bash
cd scripts
python aggregate_results.py  # Consolida todos los CSVs
python plot_results.py        # Genera grÃ¡ficas
```

## ğŸ“ˆ MÃ©tricas Evaluadas

- â±ï¸ Tiempo total de entrenamiento (10 epochs)
- ğŸš€ Speedup vs implementaciÃ³n secuencial
- ğŸ“‰ Overhead de paralelizaciÃ³n
- ğŸ“Š Ley de Amdahl
- ğŸ¯ Accuracy y Loss final
- ğŸ’¾ Transferencia Hostâ†”Device (GPU)

## ğŸ“š DocumentaciÃ³n Completa

**ğŸ“– Lee [`docs/experiment_design.md`](docs/experiment_design.md)** para:

- âœ… FundamentaciÃ³n matemÃ¡tica (forward/backward propagation)
- âœ… Detalles de implementaciÃ³n por mÃ³dulo
- âœ… Protocolo de validaciÃ³n
- âœ… DivisiÃ³n de responsabilidades
- âœ… Cronograma del proyecto
- âœ… Formato de resultados y CSVs

## âš ï¸ Restricciones

**NO se permite**:

- âŒ TensorFlow, Keras, PyTorch
- âŒ LibrerÃ­as de Deep Learning pre-construidas
- âŒ BLAS/LAPACK en C

**Permitido**:

- âœ… NumPy (solo para Python)
- âœ… OpenMP, CUDA
- âœ… LibrerÃ­as estÃ¡ndar (stdio, stdlib, math)

## ğŸ“ Estado del Proyecto

- [x] âœ… Fase 0: Estructura y documentaciÃ³n
- [ ] ğŸ”„ Fase 1: Implementaciones secuenciales
- [ ] â³ Fase 2: ParalelizaciÃ³n en CPU
- [ ] â³ Fase 3: ParalelizaciÃ³n en GPU
- [ ] â³ Fase 4: AnÃ¡lisis y grÃ¡ficas
- [ ] â³ Fase 5: Informe y presentaciÃ³n

## ğŸ‘¥ Equipo

- **C/OpenMP**: [Tu nombre]
- **Python/PyCUDA**: [Nombre compaÃ±ero]

## ğŸ“„ Proyecto AcadÃ©mico

Universidad de Caldas  
ProgramaciÃ³n Concurrente y Distribuida - 2025

## ğŸ”— Enlaces Ãštiles

- [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)
- [OpenMP Documentation](https://www.openmp.org/)
- [PyCUDA Documentation](https://documen.tician.de/pycuda/)
