# üéì GU√çA COMPLETA DEL PROYECTO MLP-MNIST CONCURRENTE

**Estudiante**: Carlos G√≥mez  
**Fecha**: 8 de diciembre de 2025  
**Rama actual**: `dev` (C + OpenMP + Frontend/Backend)  
**Compa√±ero**: Rama `devS` (Python secuencial + multiprocessing)

---

## üìä RESUMEN EJECUTIVO

### ¬øQu√© es este proyecto?

Es una implementaci√≥n **desde cero** de una **Red Neuronal MLP** _(Multilayer Perceptron = Perceptr√≥n Multicapa: red neuronal artificial con m√∫ltiples capas de neuronas conectadas)_ para clasificar d√≠gitos escritos a mano del **dataset MNIST** _(Modified National Institute of Standards and Technology: colecci√≥n de 70,000 im√°genes de d√≠gitos del 0-9 escritos a mano, est√°ndar para aprender Machine Learning)_.

El objetivo **NO es la precisi√≥n** _(lograr el mayor % de aciertos)_, sino **comparar el rendimiento** _(velocidad de ejecuci√≥n)_ **de diferentes paradigmas de programaci√≥n concurrente** _(formas de ejecutar c√≥digo en paralelo: con hilos, procesos, GPU, etc.)_.

### Arquitectura de la Red Neuronal

```
ENTRADA (784 neuronas)  ‚Üí  OCULTA (512 neuronas, ReLU)  ‚Üí  SALIDA (10 neuronas, Softmax)
     28x28 p√≠xeles              Aprende patrones              0,1,2,3,4,5,6,7,8,9
```

**Explicaci√≥n de componentes**:

- **784 neuronas de entrada**: Cada p√≠xel de la imagen 28√ó28 = 784 valores
- **ReLU** _(Rectified Linear Unit)_: Funci√≥n de activaci√≥n que convierte negativos en cero: `f(x) = max(0, x)`. Ayuda a la red a aprender patrones no lineales
- **Softmax**: Funci√≥n que convierte n√∫meros en probabilidades que suman 100%. Ej: [0.05, 0.02, 0.87, ...] = 5% es un "0", 2% es un "1", 87% es un "2"

### Implementaciones Requeridas (6 versiones)

| #   | Versi√≥n                | Estado           | Responsable | Speedup Esperado   |
| --- | ---------------------- | ---------------- | ----------- | ------------------ |
| 1a  | Python Secuencial      | ‚úÖ **INTEGRADO** | Compa√±ero   | Baseline (1.0√ó)    |
| 1b  | **C Secuencial**       | ‚úÖ **T√ö**        | **T√ö**      | 2-3√ó vs Python     |
| 2a  | Python Multiprocessing | ‚úÖ **INTEGRADO** | Compa√±ero   | 2-4√ó vs Python seq |
| 2b  | **C + OpenMP**         | ‚úÖ **T√ö**        | **T√ö**      | **4-8√ó vs C seq**  |
| 3a  | CUDA (C++)             | ‚è≥ Pendiente     | Ambos       | 10-50√ó             |
| 3b  | PyCUDA (Python)        | ‚è≥ Pendiente     | Ambos       | 8-30√ó              |

**Glosario de t√©rminos**:

- **Baseline** _(l√≠nea base)_: Versi√≥n de referencia para comparar. Su speedup es 1.0√ó (se compara consigo misma)
- **Speedup** _(aceleraci√≥n)_: Cu√°nto m√°s r√°pido corre. Ej: 4√ó = 4 veces m√°s r√°pido = tarda 1/4 del tiempo
- **Secuencial**: C√≥digo que ejecuta una instrucci√≥n a la vez (sin paralelismo)
- **Multiprocessing**: Paralelismo usando m√∫ltiples procesos separados (cada uno con su propia memoria)
- **OpenMP** _(Open Multi-Processing)_: Librer√≠a para paralelizar c√≥digo C/C++ usando hilos (threads que comparten memoria)
- **CUDA**: Plataforma de NVIDIA para programar GPUs (miles de n√∫cleos peque√±os trabajando juntos)
- **PyCUDA**: Versi√≥n de CUDA para Python

---

## üèóÔ∏è ARQUITECTURA T√âCNICA

### Backend (Integrado - rama `dev`)

#### 1. **Python Secuencial** (`backend/py_secuencial/`)

- **Prop√≥sito**: Baseline _(versi√≥n de referencia)_ en Python, implementaci√≥n est√°ndar sin optimizaciones
- **Componentes**:
  - `src/mlp.py`: Clase MLP con **Forward** _(calcular predicci√≥n)_ y **Backward** _(calcular errores para aprender)_
  - `src/data_loader.py`: Carga MNIST desde formatos **IDX** _(formato original del dataset)_ o **BIN** _(formato binario personalizado para C)_
  - `src/train.py`: **Loop de entrenamiento** _(ciclo que repite el proceso de aprender epoch por epoch)_
- **Ejecutar**:

```bash
cd backend/py_secuencial/src
python train.py --epochs 10 --batch-size 256
# --epochs: n√∫mero de veces que la red ve TODO el dataset (10 pasadas completas)
# --batch-size: cu√°ntas im√°genes procesar juntas antes de actualizar pesos (256 im√°genes a la vez)
```

#### 2. **Python Multiprocessing** (`backend/py_multiprocessing/`)

- **Prop√≥sito**: Paralelizaci√≥n con **procesos** _(programas separados que NO comparten memoria)_ = memoria distribuida
- **Estrategia**: Divisi√≥n de **mini-batches** _(peque√±os grupos de im√°genes)_ entre **workers** _(procesos trabajadores)_
- **Ejecutar**:

```bash
cd backend/py_multiprocessing/src
python train_mp.py --epochs 10 --workers 4
# --workers: n√∫mero de procesos paralelos (4 = usa 4 n√∫cleos de CPU)
```

#### 3. **C Secuencial** (`backend/c_secuencial/`)

- **Prop√≥sito**: Baseline en C, m√°s r√°pido que Python (c√≥digo compilado) pero sin paralelizaci√≥n
- **Componentes**:
  - `include/matrix.h`: Multiplicaci√≥n de matrices (**GEMM** = _General Matrix Multiply_, operaci√≥n matem√°tica m√°s costosa de la red)\*
  - `include/mlp.h`: **Forward propagation** _(calcular predicci√≥n capa por capa)_ y **Backward propagation** _(calcular gradientes = direcci√≥n del error para corregir pesos)_
  - `include/data.h`: Carga de archivos `.bin` _(binarios con las im√°genes preprocesadas)_
  - `src/train.c`: Loop de entrenamiento (10 **epochs** = _pasadas completas por el dataset_)
  - `src/export_weights.c`: Exporta **pesos** _(par√°metros aprendidos W1, W2, b1, b2)_ a **JSON** _(formato legible para JavaScript)_ para el frontend

**Compilar y ejecutar**:

```bash
cd backend/c_secuencial
make
./bin/train_seq.exe
```

**Salida**:

- `backend/results/raw/c_sequential.csv` (m√©tricas por √©poca)
- `backend/api/model_weights_sequential.json` (pesos para frontend)

#### 4. **C + OpenMP** (`backend/c_openmp/`)

- **Prop√≥sito**: Paralelizaci√≥n con **hilos** _(threads: mini-procesos livianos que comparten la misma memoria)_ = memoria compartida
- **Optimizaciones**:
  - `#pragma omp parallel for`: **Directiva** _(instrucci√≥n especial)_ de OpenMP que divide un bucle entre varios hilos autom√°ticamente
  - Paralelizaci√≥n del **batch processing** _(procesar m√∫ltiples lotes de im√°genes simult√°neamente)_
  - Uso de `OMP_NUM_THREADS`: **Variable de entorno** _(configuraci√≥n del sistema)_ que controla cu√°ntos hilos usar (ej: 8 = usar 8 n√∫cleos de CPU)

**Compilar y ejecutar**:

```bash
cd backend/c_openmp
make
export OMP_NUM_THREADS=8  # En Windows: set OMP_NUM_THREADS=8
./bin/train_openmp.exe
```

**Salida**:

- `backend/results/raw/c_openmp.csv`
- `backend/api/model_weights_openmp.json`

#### 5. **API Node.js** (`backend/api/`)

- **Prop√≥sito**: Servidor **REST** _(Representational State Transfer: estilo de comunicaci√≥n web donde el cliente hace peticiones HTTP)_ para que el frontend haga predicciones
- **Endpoints** _(URLs espec√≠ficas que el servidor entiende)_:
  - `GET /api/health`: **GET** _(solicitar informaci√≥n)_ para verificar si el servidor est√° funcionando
  - `GET /api/models`: Listar modelos disponibles (sequential, openmp)
  - `POST /api/predict`: **POST** _(enviar datos)_ una imagen y recibir la predicci√≥n del d√≠gito

**Iniciar**:

```bash
cd backend/api
npm install
npm start  # Puerto 3001
```

#### 6. **Frontend React** (`frontend/`)

- **Prop√≥sito**: Interfaz gr√°fica de usuario para dibujar y predecir d√≠gitos
- **Caracter√≠sticas**:
  - **Canvas** _(lienzo HTML5)_: √Årea de dibujo que captura trazos del mouse y los convierte a imagen 28√ó28 p√≠xeles
  - Selecci√≥n de modelo (Sequential/OpenMP): Dropdown para elegir qu√© versi√≥n de la red usar
  - Visualizaci√≥n de **probabilidades** _(% de confianza de cada d√≠gito 0-9)_: Gr√°fico de barras mostrando qu√© tan segura est√° la red

**Iniciar**:

```bash
cd frontend
npm install
npm run dev  # Puerto 5173
```

### Dataset (`backend/data/mnist/`)

**Archivos generados por scripts Python**:

- `train_images.bin`: 60,000 im√°genes para entrenar (180 MB)
- `train_labels.bin`: 60,000 **etiquetas one-hot** _(representaci√≥n donde el d√≠gito correcto es 1 y el resto 0. Ej: "3" = [0,0,0,1,0,0,0,0,0,0])_ (2.4 MB)
- `test_images.bin`: 10,000 im√°genes para validar (30 MB)
- `test_labels.bin`: 10,000 etiquetas one-hot para validaci√≥n (0.4 MB)

**‚ö†Ô∏è Estos archivos NO est√°n en el repositorio** (son generados localmente).

---

## üîÑ GESTI√ìN DE GIT

### Estado Actual

**Tu rama `dev` (‚úÖ ACTUALIZADA)**:

- ‚úÖ C√≥digo Python integrado desde `devS`
- ‚úÖ Frontend completo y funcional
- ‚úÖ API refactorizada para m√∫ltiples modelos
- ‚úÖ Exportaci√≥n de pesos mejorada
- ‚úÖ Archivos binarios excluidos de Git
- ‚úÖ Todo pusheado exitosamente a GitHub

**Estructura Completa**:

- `backend/py_secuencial/` - Python baseline
- `backend/py_multiprocessing/` - Python paralelo
- `backend/c_secuencial/` - C baseline
- `backend/c_openmp/` - C paralelo (4.45√ó speedup)
- `backend/api/` - Node.js REST API
- `frontend/` - React UI

### Integraci√≥n Completada ‚úÖ

**Lo que se hizo**:

```bash
# ‚úÖ PASO 1: Guardado de trabajo
git add .
git commit -m "feat: Frontend React + API Node.js + exportaci√≥n mejorada"

# ‚úÖ PASO 2: Limpieza de archivos binarios
git filter-branch --force --index-filter 'git rm --cached --ignore-unmatch backend/data/mnist/*.bin backend/data/mnist/*ubyte'
git push --force-with-lease origin dev

# ‚úÖ PASO 3: Integraci√≥n de c√≥digo Python (cherry-pick)
git checkout -b dev-integration
git checkout origin/devS -- py_secuencial py_multiprocessing
mv py_secuencial backend/
mv py_multiprocessing backend/
# Ajuste de rutas en archivos Python
git add backend/py_*
git commit -m "feat: Integrar Python desde devS"

# ‚úÖ PASO 4: Merge y push
git checkout dev
git merge dev-integration
git push origin dev
```

**Resultado**: Todas las implementaciones Python est√°n en `backend/` con rutas corregidas.

---

## üìê MATEM√ÅTICAS DEL MLP

### Forward Propagation (Predicci√≥n)

**Notaci√≥n**:

- `@` = multiplicaci√≥n de matrices
- `(batch, 512)` = dimensiones de la matriz (filas, columnas)
- `W1, W2` = matrices de pesos (par√°metros aprendidos)
- `b1, b2` = vectores de bias (desplazamiento aprendido)

```
1. Z1 = X @ W1 + b1        # (batch, 512) = (batch, 784) @ (784, 512) + (512,)
   # Cada imagen (784 p√≠xeles) se multiplica por pesos W1 para obtener 512 valores

2. A1 = ReLU(Z1)           # A1[i] = max(0, Z1[i])
   # ReLU convierte negativos en cero, mantiene positivos

3. Z2 = A1 @ W2 + b2       # (batch, 10) = (batch, 512) @ (512, 10) + (10,)
   # 512 valores se multiplican por pesos W2 para obtener 10 valores (uno por d√≠gito)

4. A2 = Softmax(Z2)        # A2[j] = exp(Z2[j]) / sum(exp(Z2))
   # Softmax convierte los 10 valores en probabilidades que suman 1.0 (100%)
```

### Backward Propagation (Aprendizaje)

**Notaci√≥n**:

- `dZ, dW, db` = **gradientes** _(derivadas que indican cu√°nto cambiar cada par√°metro)_
- `^T` = **transpuesta** _(voltear filas y columnas de una matriz)_
- `‚äô` = multiplicaci√≥n elemento a elemento (Hadamard)
- `Y_true` = etiqueta correcta (respuesta esperada)

```
1. dZ2 = A2 - Y_true          # (batch, 10) Error en la salida
   # Diferencia entre predicci√≥n (A2) y realidad (Y_true)

2. dW2 = A1^T @ dZ2 / batch   # (512, 10) Gradiente de W2
   # Calcula cu√°nto contribuy√≥ cada peso W2 al error

3. db2 = sum(dZ2) / batch     # (10,) Gradiente de b2
   # Suma de errores para cada neurona de salida

4. dA1 = dZ2 @ W2^T           # (batch, 512) Error propagado hacia atr√°s
   # Distribuye el error de salida hacia la capa oculta

5. dZ1 = dA1 ‚äô ReLU'(Z1)     # (batch, 512) ‚äô = multiplicaci√≥n elemento a elemento
   # ReLU'(x) = 1 si x>0, 0 si x‚â§0 (derivada de ReLU)

6. dW1 = X^T @ dZ1 / batch    # (784, 512) Gradiente de W1
   # Calcula cu√°nto contribuy√≥ cada peso W1 al error

7. db1 = sum(dZ1) / batch     # (512,) Gradiente de b1
   # Suma de errores para cada neurona oculta
```

### Actualizaci√≥n de Pesos

**Œ± (alpha)** = **learning rate** _(tasa de aprendizaje)_: qu√© tan grande es cada paso de correcci√≥n

- Si Œ± es muy grande (ej: 1.0) ‚Üí aprende r√°pido pero puede pasarse
- Si Œ± es muy peque√±o (ej: 0.0001) ‚Üí aprende lento pero con precisi√≥n
- 0.01 es un buen balance

```
W1 = W1 - Œ± * dW1   # Resta el gradiente escalado por Œ±
                     # Ejemplo: si dW1=2 y Œ±=0.01, resta 0.02
b1 = b1 - Œ± * db1   # Lo mismo para bias
W2 = W2 - Œ± * dW2
b2 = b2 - Œ± * db2
```

**Intuici√≥n**: Los gradientes indican "hacia d√≥nde subir el error", as√≠ que restamos para bajar el error.

### Cuello de Botella Computacional

**El 95% del tiempo est√° en la multiplicaci√≥n de matrices**:

- `X @ W1`: (batch, 784) √ó (784, 512) = **401,408 operaciones/imagen**
- `A1 @ W2`: (batch, 512) √ó (512, 10) = **5,120 operaciones/imagen**

**Por eso se paraleliza la multiplicaci√≥n de matrices**.

---

## ‚ö° PARALELIZACI√ìN (Tu contribuci√≥n principal)

### OpenMP: Estrategias Implementadas

#### 1. Paralelizaci√≥n de GEMM (General Matrix Multiply)

```c
// ANTES (Secuencial)
for (int i = 0; i < M; i++) {              // M filas
    for (int j = 0; j < N; j++) {          // N columnas
        float sum = 0.0f;
        for (int k = 0; k < K; k++) {      // K elementos a sumar
            sum += A[i*K + k] * B[k*N + j];
        }
        C[i*N + j] = sum;                   // Resultado en C[i][j]
    }
}
// Esto ejecuta M√óN√óK operaciones en serie (uno tras otro)

// DESPU√âS (Paralelo con OpenMP)
#pragma omp parallel for collapse(2) schedule(dynamic)
for (int i = 0; i < M; i++) {
    for (int j = 0; j < N; j++) {
        float sum = 0.0f;
        for (int k = 0; k < K; k++) {
            sum += A[i*K + k] * B[k*N + j];
        }
        C[i*N + j] = sum;
    }
}
// OpenMP divide el trabajo entre m√∫ltiples hilos autom√°ticamente
```

**Explicaci√≥n de directivas OpenMP**:

- **`#pragma omp parallel for`**: Directiva que dice "divide este bucle entre varios hilos"
- **`collapse(2)`**: Combina los 2 loops externos (i y j) en uno solo ‚Üí m√°s iteraciones = mejor distribuci√≥n entre hilos
  - Sin collapse: 512 iteraciones (solo i)
  - Con collapse(2): 512√ó10 = 5,120 iteraciones (i√ój)
- **`schedule(dynamic)`**: Estrategia de distribuci√≥n din√°mica
  - **static** _(est√°tico)_: Divide las iteraciones equitativamente al inicio (r√°pido pero puede desbalancearse)
  - **dynamic** _(din√°mico)_: Los hilos toman trabajo seg√∫n terminan (mejor balance, peque√±o overhead)

#### 2. Reducci√≥n Paralela para Gradientes

```c
#pragma omp parallel for reduction(+:db2[:OUTPUT_SIZE])
for (int i = 0; i < batch_size; i++) {
    for (int j = 0; j < OUTPUT_SIZE; j++) {
        db2[j] += gradients[i * OUTPUT_SIZE + j];
    }
}
// Suma los gradientes de todas las im√°genes del batch
```

**Explicaci√≥n de `reduction`**:

- **Problema sin reduction**: Si m√∫ltiples hilos suman a `db2[j]` simult√°neamente ‚Üí **race condition** _(conflicto: dos hilos leen/escriben al mismo tiempo, resultado incorrecto)_
- **Soluci√≥n con reduction**:
  1. Cada hilo crea su propia copia privada de `db2`
  2. Cada hilo suma en su copia (sin conflictos)
  3. Al final, OpenMP combina todas las copias sum√°ndolas
- **`reduction(+:db2[:OUTPUT_SIZE])`**: Operador `+` (suma), variable `db2`, tama√±o `OUTPUT_SIZE` (10 elementos)

**Alternativa sin reduction** _(m√°s lenta)_:

````c
#pragma omp parallel for
for (int i = 0; i < batch_size; i++) {
    #pragma omp critical  // Solo un hilo a la vez puede entrar aqu√≠
    for (int j = 0; j < OUTPUT_SIZE; j++) {
        db2[j] += gradients[i * OUTPUT_SIZE + j];
    }
}
// Critical crea un cuello de botella (serializa el trabajo)

### Escalabilidad Medida

| Hilos | Tiempo (s) | Speedup   | Eficiencia |
| ----- | ---------- | --------- | ---------- |
| 1     | 1539       | 1.0√ó      | 100%       |
| 2     | 820        | 1.88√ó     | 94%        |
| 4     | 450        | 3.42√ó     | 86%        |
| 8     | 346        | **4.45√ó** | 56%        |

**C√≥mo se calculan**:
- **Speedup** = Tiempo(1 hilo) / Tiempo(N hilos)
  - Ej: 1539s / 346s = 4.45√ó
- **Eficiencia** = Speedup / N√∫mero de hilos √ó 100%
  - Ej: 4.45 / 8 √ó 100% = 56%
  - **Eficiencia 100%** = speedup lineal ideal (doblar hilos = mitad de tiempo)
  - **Eficiencia <100%** = hay partes que no se pueden paralelizar + overhead

**Observaci√≥n**: La eficiencia baja al aumentar hilos debido a:
1. **Ley de Amdahl**: Siempre hay una porci√≥n secuencial (S) que no se paraleliza
   - Speedup m√°ximo = 1 / S
   - Si 5% es secuencial ‚Üí speedup m√°ximo = 1/0.05 = 20√ó
2. **Overhead** *(costo extra)*: Crear hilos, sincronizar, combinar resultados
3. **Contenci√≥n de memoria** *(cuellos de botella)*: M√∫ltiples hilos accediendo a la misma RAM

---

## üß™ EXPERIMENTOS Y M√âTRICAS

### M√©tricas a Recopilar

Para cada implementaci√≥n, registra en `results/raw/<nombre>.csv`:

```csv
epoch,train_loss,train_accuracy,test_accuracy,time_seconds
1,0.532,0.842,0.838,154.3
2,0.321,0.906,0.901,152.1
...
````

### Gr√°ficas del Informe

#### 1. Speedup vs. N√∫mero de Hilos (OpenMP)

```
Speedup
   8√ó  ‚î§
   7√ó  ‚î§                           ‚ï± Ideal (lineal)
   6√ó  ‚î§                        ‚ï±
   5√ó  ‚î§                     ‚ï±
   4√ó  ‚î§                  ‚ï±‚Ä¢‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Real (4.45√ó)
   3√ó  ‚î§               ‚ï±‚Ä¢
   2√ó  ‚î§            ‚ï±‚Ä¢
   1√ó  ‚î§‚Ä¢‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Ä¢
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
       1  2  4  6  8  10  12  14  Hilos
```

**An√°lisis**: ¬øPor qu√© no es lineal? (Overhead, sincronizaci√≥n, Amdahl)

#### 2. Comparaci√≥n de Tiempos

```
Tiempo (segundos)
2000 ‚î§ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  Python Seq (1800s)
1500 ‚î§ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     C Seq (1539s)
1000 ‚î§ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             Python MP (900s)
 500 ‚î§ ‚ñà‚ñà‚ñà‚ñà                  C OpenMP (346s)
   0 ‚î§
```

#### 3. Profiling GPU (futuro)

```
Transfer CPU‚ÜíGPU:  15% (120ms)
Kernel Execution:  70% (560ms)
Transfer GPU‚ÜíCPU:  10% (80ms)
Overhead:           5% (40ms)
```

---

## üé§ GU√çA DE SUSTENTACI√ìN

### ¬øNecesitas Frontend/Backend?

**Para la sustentaci√≥n acad√©mica: NO ES OBLIGATORIO**

El proyecto requiere:

1. ‚úÖ **C√≥digo fuente** de las 6 implementaciones
2. ‚úÖ **Informe t√©cnico** con m√©tricas y an√°lisis
3. ‚úÖ **Presentaci√≥n oral** (10-15 min)

**El frontend es un EXTRA** que demuestra que el modelo funciona, pero puedes sustentar solo con:

- Terminal mostrando el entrenamiento
- CSVs con m√©tricas
- Gr√°ficas en el informe

### C√≥mo Usar Todo Manualmente (sin Frontend)

#### Escenario 1: Solo entrenar y ver m√©tricas

```bash
# 1. Entrenar modelo C Secuencial
cd backend/c_secuencial
make
./bin/train_seq.exe

# Ver√°s en consola:
# Epoch 1/10: Loss=0.532, Train Acc=84.2%, Test Acc=83.8% (154s)
# Epoch 2/10: Loss=0.321, Train Acc=90.6%, Test Acc=90.1% (152s)
# ...

# 2. Entrenar modelo C OpenMP (8 hilos)
cd ../c_openmp
make
set OMP_NUM_THREADS=8
./bin/train_openmp.exe

# 3. Ver resultados en CSV
cat backend/results/raw/c_sequential.csv
cat backend/results/raw/c_openmp.csv

# 4. Generar gr√°ficas con Python
cd backend/scripts
python plot_results.py  # (si tienes este script)
```

#### Escenario 2: Mostrar predicciones en vivo

**Opci√≥n A: Con Frontend (m√°s bonito)**

```bash
# Terminal 1: API
cd backend/api
npm start

# Terminal 2: Frontend
cd frontend
npm run dev

# Navegador: http://localhost:5173
# Dibujas un "7" ‚Üí Modelo predice "7 (95%)"
```

**Opci√≥n B: Sin Frontend (solo API + curl)**

```bash
# Terminal 1: API
cd backend/api
npm start

# Terminal 2: Probar predicci√≥n
curl -X POST http://localhost:3001/api/predict \
  -H "Content-Type: application/json" \
  -d '{
    "modelId": "openmp",
    "image": [0,0,0,...,255,...,0]  # Array de 784 valores (0-255)
  }'

# Respuesta:
# {"success":true,"prediction":7,"probabilities":[0.01,0.02,...,0.95,...]}
```

**Opci√≥n C: Solo l√≠nea de comandos (test.c)**

Crea un peque√±o programa que cargue los pesos y prediga una imagen:

```c
// test_prediction.c
#include "mlp.h"
#include "data.h"

int main() {
    MLP mlp;
    mlp_load_weights(&mlp, "model_weights_openmp.json");

    // Cargar imagen de prueba (por ej. la #0 del test set)
    float image[784];
    load_test_image(0, image);

    // Predecir
    float output[10];
    mlp_forward(&mlp, image, output);

    // Mostrar
    int predicted = argmax(output, 10);
    printf("Imagen #0: Predicci√≥n = %d (confianza: %.2f%%)\n",
           predicted, output[predicted]*100);
}
```

### Estructura de la Presentaci√≥n (10-15 min)

#### Diapositiva 1: Portada

- T√≠tulo del proyecto
- Nombres
- Fecha

#### Diapositiva 2: Contexto

- ¬øPor qu√© Deep Learning es costoso?
- Necesidad de paralelizaci√≥n
- Objetivo: Comparar paradigmas

#### Diapositiva 3: Arquitectura MLP

- Diagrama de 3 capas
- Ecuaciones Forward/Backward
- Cuello de botella: GEMM

#### Diapositiva 4: Implementaciones

- Tabla con las 6 versiones
- Estado actual (4/6 completadas)

#### Diapositiva 5: Metodolog√≠a

- Hardware usado (CPU, RAM, n√∫cleos)
- Hiperpar√°metros fijos
- C√≥mo se midi√≥ el tiempo

#### Diapositiva 6: Resultados - Tabla Comparativa

```
| Versi√≥n           | Tiempo | Speedup | Accuracy |
|-------------------|--------|---------|----------|
| Python Seq        | 1800s  | 1.0√ó    | 93.2%    |
| C Seq             | 1539s  | 1.17√ó   | 93.5%    |
| Python MP (4 proc)| 900s   | 2.0√ó    | 93.2%    |
| C OpenMP (8 hilos)| 346s   | 5.2√ó    | 93.5%    |
```

#### Diapositiva 7: Gr√°fica Speedup OpenMP

- Curva Real vs. Ideal
- An√°lisis de Amdahl

#### Diapositiva 8: Demo en Vivo (opcional)

- Mostrar frontend prediciendo un d√≠gito
- O ejecutar en terminal

#### Diapositiva 9: Conclusilei esto, ahoravamos probar que todo funioones

- OpenMP logr√≥ 4.45√ó con 8 hilos
- Multiprocessing tiene overhead de IPC
- GPU (futuro) promete 10-50√ó

#### Diapositiva 10: Preguntas

---

## üõ†Ô∏è C√ìMO CORRER TODO PASO A PASO

### Pre-requisitos

**Windows (MSYS2)**:

```bash
# Ya debes tener instalado (seg√∫n INSTALL_C_TOOLS.md):
- GCC con OpenMP
- Make
- Node.js + npm
- Python 3.8+
```

### Paso 1: Descargar y preprocesar MNIST

```bash
cd backend/scripts
python download_mnist.py
python preprocess_for_c.py

# Verifica:
ls backend/data/mnist/
# Deber√≠as ver: train_images.bin, train_labels.bin, etc.
```

### Paso 2: Entrenar modelos C

```bash
# Secuencial
cd backend/c_secuencial
make clean
make
./bin/train_seq.exe  # Toma ~25 min

# OpenMP (8 hilos)
cd ../c_openmp
make clean
make
set OMP_NUM_THREADS=8
./bin/train_openmp.exe  # Toma ~6 min
```

### Paso 3: Verificar exportaci√≥n de pesos

```bash
# Deben existir:
ls backend/api/model_weights_sequential.json
ls backend/api/model_weights_openmp.json
```

### Paso 4: Levantar el stack completo

```bash
# Terminal 1: API
cd backend/api
npm install
npm start  # Puerto 3001

# Terminal 2: Frontend
cd frontend
npm install
npm run dev  # Puerto 5173

# Navegador:
# http://localhost:5173
```

### Paso 5: Probar predicci√≥n

1. Dibuja un d√≠gito (ej. "5")
2. Selecciona modelo ("C OpenMP")
3. Click "Predecir"
4. Ver√°s: "Predicci√≥n: 5 (Confianza: 92%)"

---

## üî¨ AN√ÅLISIS PROFUNDO

### ¬øPor qu√© C es m√°s r√°pido que Python?

1. **Compilado vs. Interpretado**: C se compila a c√≥digo m√°quina nativo
2. **Sin GIL**: Python tiene el Global Interpreter Lock
3. **Control de memoria**: C gestiona memoria manualmente (malloc/free)
4. **Optimizaciones del compilador**: `-O3` aplica vectorizaci√≥n, loop unrolling

### ¬øPor qu√© OpenMP escala bien?

1. **Memoria compartida**: Los hilos comparten W1, W2 (no hay copia)
2. **Granularidad gruesa**: Cada hilo procesa m√∫ltiples filas de la matriz
3. **Buen locality**: Accesos a memoria son secuenciales (cache-friendly)

### ¬øQu√© limita el Speedup? (Ley de Amdahl)

```
Speedup = 1 / (S + P/N)

S = Fracci√≥n secuencial (ej. 0.05 = 5%)
P = Fracci√≥n paralelizable (ej. 0.95 = 95%)
N = N√∫mero de hilos

Ejemplo con 8 hilos:
Speedup = 1 / (0.05 + 0.95/8) = 1 / 0.169 = 5.92√ó

Real: 4.45√ó (porque overhead de sincronizaci√≥n)
```

**Partes secuenciales**:

- Carga de datos
- Escritura de logs
- Actualizaci√≥n de pesos (tiene secci√≥n cr√≠tica)

---

## üìù CHECKLIST DE ENTREGA

### C√≥digo Fuente ‚úÖ

```
‚úÖ backend/py_secuencial/       (Python + NumPy)
‚úÖ backend/py_multiprocessing/  (Python + multiprocessing)
‚úÖ backend/c_secuencial/        (compilable con make)
‚úÖ backend/c_openmp/            (compilable con make)
‚è≥ backend/pycuda_gpu/          (pendiente)
‚úÖ frontend/                    (extra, no requerido)
‚úÖ backend/api/                 (extra, no requerido)
```

### Informe T√©cnico (Word/PDF)

```
[ ] 1. Introducci√≥n (contexto, objetivos)
[ ] 2. Arquitectura MLP (diagrama, ecuaciones)
[ ] 3. Metodolog√≠a (hardware, hiperpar√°metros)
[ ] 4. Resultados:
    [ ] 4.1 Tabla comparativa de tiempos
    [ ] 4.2 Gr√°fica Speedup OpenMP
    [ ] 4.3 An√°lisis Ley de Amdahl
    [ ] 4.4 Comparaci√≥n Python MP vs. C OpenMP
    [ ] 4.5 Profiling GPU (si completan CUDA)
[ ] 5. Conclusiones
[ ] 6. Referencias
```

### Presentaci√≥n (PPT/PDF)

```
[ ] 10-12 diapositivas
[ ] M√°ximo 15 minutos
[ ] Todos los miembros participan
[ ] Incluir gr√°ficas del informe
```

---

## üö® PROBLEMAS COMUNES

### 1. "No se encuentran archivos .bin"

**Soluci√≥n**:

```bash
cd backend/scripts
python preprocess_for_c.py
```

### 2. "OpenMP no compila"

**Soluci√≥n**:

```bash
# Verifica que gcc soporte OpenMP:
gcc -fopenmp --version

# Si no, reinstala gcc con MSYS2:
pacman -S mingw-w64-x86_64-gcc
```

### 3. "Frontend no se conecta a la API"

**Soluci√≥n**:

```bash
# Verifica que la API est√© corriendo:
curl http://localhost:3001/api/health

# Si no responde, revisa que:
# 1. npm start est√© corriendo en backend/api
# 2. No haya otro proceso en puerto 3001
```

### 4. "Accuracy es muy bajo (<80%)"

**Causas**:

- Pesos inicializados incorrectamente
- Learning rate muy alto/bajo
- Bug en backpropagation

**Debug**:

```bash
# Compara pesos de √©poca 1 con implementaci√≥n conocida
# Verifica que la loss disminuya cada √©poca
```

---

## üéØ PR√ìXIMOS PASOS

### Inmediato (antes de sustentar)

1. ‚úÖ Commitear y pushear rama `dev`
2. ‚úÖ Integrar c√≥digo Python de `devS`
3. ‚è≥ Completar informe t√©cnico
4. ‚è≥ Crear presentaci√≥n
5. ‚è≥ Ensayar sustentaci√≥n

### Opcional (si hay tiempo)

6. ‚è≥ Implementar CUDA/PyCUDA
7. ‚è≥ Mejorar visualizaciones del frontend
8. ‚è≥ Agregar m√°s gr√°ficas al informe

---

## üìö RECURSOS

### Documentaci√≥n Interna

- `backend/docs/FORMULAS_IMPLEMENTACION.md`: Matem√°ticas detalladas
- `backend/docs/WORKFLOW.md`: Dependencias entre componentes
- `backend/docs/INSTALL_C_TOOLS.md`: Setup de herramientas

### Referencias Externas

- MNIST Dataset: http://yann.lecun.com/exdb/mnist/
- OpenMP Tutorial: https://computing.llnl.gov/tutorials/openMP/
- Backpropagation: http://neuralnetworksanddeeplearning.com/

---

## üí° TIPS PARA LA SUSTENTACI√ìN

### 1. Demuestra que entiendes TODO

**Pregunta t√≠pica**: "¬øPor qu√© ReLU en lugar de sigmoid?"

**Respuesta**:

> "ReLU evita el problema de vanishing gradient porque su derivada es siempre 1 (si x>0) o 0 (si x‚â§0). Sigmoid satura en los extremos, haciendo que la derivada sea casi cero y el aprendizaje se detenga."

### 2. S√© honesto sobre limitaciones

**Pregunta**: "¬øPor qu√© solo lograron 4.45√ó con 8 hilos?"

**Respuesta**:

> "Seg√∫n la Ley de Amdahl, el speedup te√≥rico m√°ximo es 1/(S + P/N). Estimamos que el 5% del c√≥digo es secuencial (carga de datos, logs). Adem√°s, hay overhead de sincronizaci√≥n en las secciones cr√≠ticas (actualizaci√≥n de pesos). Por eso no logramos el ideal de 8√ó."

### 3. Relaciona con el mundo real

**Pregunta**: "¬øC√≥mo se relaciona esto con frameworks como TensorFlow?"

**Respuesta**:

> "TensorFlow usa GEMM (multiplicaci√≥n de matrices) implementado en cuBLAS (GPU) o MKL (CPU). Nosotros implementamos GEMM desde cero para entender los cuellos de botella. En producci√≥n, siempre usar√≠amos librer√≠as optimizadas."

### 4. Demuestra el frontend (si lo tienes)

- Es visual y impresionante
- Muestra que el modelo REALMENTE funciona
- Diferencia tu proyecto del de otros grupos

### 5. Ten m√©tricas a la mano

- Speedup exacto (4.45√ó)
- Tiempo por √©poca (346s vs. 1539s)
- Accuracy final (93.5%)

---

## ‚úÖ CONCLUSI√ìN

**Lo que YA TIENES (rama `dev`) - ‚úÖ INTEGRADO**:

- ‚úÖ Python Secuencial (`backend/py_secuencial/`)
- ‚úÖ Python Multiprocessing (`backend/py_multiprocessing/`)
- ‚úÖ C Secuencial (`backend/c_secuencial/`)
- ‚úÖ C OpenMP (`backend/c_openmp/`) - **4.45√ó speedup**
- ‚úÖ Frontend React (extra, no obligatorio)
- ‚úÖ API Node.js (extra, no obligatorio)
- ‚úÖ Sistema de exportaci√≥n de pesos

**Lo que QUEDA POR HACER (ambos)**:

- CUDA/PyCUDA
- Informe t√©cnico
- Presentaci√≥n

**Para sustentar SOLO TU PARTE**:

1. Demuestra entrenamiento en C (secuencial y OpenMP)
2. Muestra gr√°fica de Speedup
3. Explica optimizaciones con OpenMP
4. (Opcional) Demo del frontend

**Tiempo estimado para preparar sustentaci√≥n**: 2-3 d√≠as

---

**¬øPreguntas? Revisa esta gu√≠a o consulta los archivos en `backend/docs/`**
