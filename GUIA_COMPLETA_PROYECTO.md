# üéì GU√çA COMPLETA DEL PROYECTO MLP-MNIST CONCURRENTE

**Estudiante**: Carlos G√≥mez  
**Fecha**: 8 de diciembre de 2025  
**Rama actual**: `dev` (C + OpenMP + Frontend/Backend)  
**Compa√±ero**: Rama `devS` (Python secuencial + multiprocessing)

---

## üìä RESUMEN EJECUTIVO

### ¬øQu√© es este proyecto?

Es una implementaci√≥n **desde cero** de una Red Neuronal MLP (Perceptr√≥n Multicapa) para clasificar d√≠gitos escritos a mano (dataset MNIST). El objetivo **NO es la precisi√≥n**, sino **comparar el rendimiento de diferentes paradigmas de programaci√≥n concurrente**.

### Arquitectura de la Red Neuronal

```
ENTRADA (784 neuronas)  ‚Üí  OCULTA (512 neuronas, ReLU)  ‚Üí  SALIDA (10 neuronas, Softmax)
     28x28 p√≠xeles              Aprende patrones              0,1,2,3,4,5,6,7,8,9
```

### Implementaciones Requeridas (6 versiones)

| #   | Versi√≥n                | Estado       | Responsable | Speedup Esperado   |
| --- | ---------------------- | ------------ | ----------- | ------------------ |
| 1a  | Python Secuencial      | ‚úÖ En `devS` | Compa√±ero   | Baseline (1.0√ó)    |
| 1b  | **C Secuencial**       | ‚úÖ **T√ö**    | **T√ö**      | 2-3√ó vs Python     |
| 2a  | Python Multiprocessing | ‚úÖ En `devS` | Compa√±ero   | 2-4√ó vs Python seq |
| 2b  | **C + OpenMP**         | ‚úÖ **T√ö**    | **T√ö**      | **4-8√ó vs C seq**  |
| 3a  | CUDA (C++)             | ‚è≥ Pendiente | Ambos       | 10-50√ó             |
| 3b  | PyCUDA (Python)        | ‚è≥ Pendiente | Ambos       | 8-30√ó              |

---

## üèóÔ∏è ARQUITECTURA T√âCNICA

### Backend (Tu parte - rama `dev`)

#### 1. **C Secuencial** (`backend/c_secuencial/`)

- **Prop√≥sito**: Baseline en C, m√°s r√°pido que Python pero sin paralelizaci√≥n
- **Componentes**:
  - `include/matrix.h`: Multiplicaci√≥n de matrices (GEMM)
  - `include/mlp.h`: Forward/Backward propagation
  - `include/data.h`: Carga de archivos `.bin` del dataset
  - `src/train.c`: Loop de entrenamiento (10 epochs)
  - `src/export_weights.c`: Exporta pesos a JSON para el frontend

**Compilar y ejecutar**:

```bash
cd backend/c_secuencial
make
./bin/train_seq.exe
```

**Salida**:

- `backend/results/raw/c_sequential.csv` (m√©tricas por √©poca)
- `backend/api/model_weights_sequential.json` (pesos para frontend)

#### 2. **C + OpenMP** (`backend/c_openmp/`)

- **Prop√≥sito**: Paralelizaci√≥n con hilos (memoria compartida)
- **Optimizaciones**:
  - `#pragma omp parallel for` en multiplicaci√≥n de matrices
  - Paralelizaci√≥n del batch processing
  - Uso de `OMP_NUM_THREADS` para escalar

**Compilar y ejecutar**:

```bash
cd backend/c_openmp
make
export OMP_NUM_THREADS=8  # En Windows: set OMP_NUM_THREADS=8
./bin/train_openmp.exe
```

**Salida**:

- `backend/results/raw/c_openmp.csv`
- `backend/api/model_weights_openmp.json`

#### 3. **API Node.js** (`backend/api/`)

- **Prop√≥sito**: Servidor REST para que el frontend haga predicciones
- **Endpoints**:
  - `GET /api/health`: Verificar servidor
  - `GET /api/models`: Listar modelos disponibles
  - `POST /api/predict`: Predecir d√≠gito

**Iniciar**:

```bash
cd backend/api
npm install
npm start  # Puerto 3001
```

#### 4. **Frontend React** (`frontend/`)

- **Prop√≥sito**: Interfaz para dibujar y predecir d√≠gitos
- **Caracter√≠sticas**:
  - Canvas para dibujar (28√ó28)
  - Selecci√≥n de modelo (Sequential/OpenMP)
  - Visualizaci√≥n de probabilidades

**Iniciar**:

```bash
cd frontend
npm install
npm run dev  # Puerto 5173
```

### Dataset (`backend/data/mnist/`)

**Archivos generados por scripts Python**:

- `train_images.bin`: 60,000 im√°genes (180 MB)
- `train_labels.bin`: 60,000 etiquetas one-hot (2.4 MB)
- `test_images.bin`: 10,000 im√°genes (30 MB)
- `test_labels.bin`: 10,000 etiquetas (0.4 MB)

**‚ö†Ô∏è Estos archivos NO est√°n en el repositorio** (son generados localmente).

---

## üîÑ GESTI√ìN DE GIT

### Estado Actual

**Tu rama `dev`**:

- 1 commit adelante de `origin/dev`
- Cambios sin commitear:
  - ‚úÖ Frontend completo
  - ‚úÖ API refactorizada
  - ‚úÖ Exportaci√≥n de pesos mejorada
  - ‚ö†Ô∏è Archivos eliminados: `CHECKLIST.md`, `RESUMEN.md`, `start.sh`

**Rama `devS` (compa√±ero)**:

- Contiene Python secuencial y multiprocessing
- Movi√≥ carpetas `c_*` a la ra√≠z (diferente estructura)
- Elimin√≥ todo el frontend y API

### Plan de Integraci√≥n

```bash
# PASO 1: Commitear tus cambios actuales
cd "c:\Users\carli\OneDrive\Desktop\Universidad de Caldas\Semestre VII\Concurrentes\Proyecto\mlp-mnist-concurrente"

git add .
git commit -m "feat: Frontend React + API Node.js + exportaci√≥n de pesos mejorada"

# PASO 2: Pushear tu rama dev
git push origin dev

# PASO 3: Traer los cambios de Python (devS) SIN sobrescribir tu trabajo
# Opci√≥n A: Merge (recomendado)
git merge origin/devS -m "merge: Integrar implementaciones Python de devS"

# Si hay conflictos (es probable), Git te avisar√°
# Los conflictos estar√°n en archivos que ambos modificaron

# Opci√≥n B: Cherry-pick (m√°s control)
# Solo traer los archivos de Python sin tocar tu estructura
git checkout origin/devS -- py_secuencial
git checkout origin/devS -- py_multiprocessing
git commit -m "feat: Agregar implementaciones Python desde devS"

# PASO 4: Verificar estructura final
ls
```

**‚ö†Ô∏è RECOMENDACI√ìN**: Usa la **Opci√≥n B (cherry-pick)** porque `devS` tiene una estructura diferente (movi√≥ carpetas) y podr√≠a romper tu frontend/backend.

---

## üìê MATEM√ÅTICAS DEL MLP

### Forward Propagation (Predicci√≥n)

```
1. Z1 = X @ W1 + b1        # (batch, 512) = (batch, 784) @ (784, 512) + (512,)
2. A1 = ReLU(Z1)           # A1[i] = max(0, Z1[i])
3. Z2 = A1 @ W2 + b2       # (batch, 10) = (batch, 512) @ (512, 10) + (10,)
4. A2 = Softmax(Z2)        # A2[j] = exp(Z2[j]) / sum(exp(Z2))
```

### Backward Propagation (Aprendizaje)

```
1. dZ2 = A2 - Y_true          # (batch, 10) Error en la salida
2. dW2 = A1^T @ dZ2 / batch   # (512, 10) Gradiente de W2
3. db2 = sum(dZ2) / batch     # (10,) Gradiente de b2
4. dA1 = dZ2 @ W2^T           # (batch, 512) Error propagado
5. dZ1 = dA1 ‚äô ReLU'(Z1)     # (batch, 512) ‚äô = elemento a elemento
6. dW1 = X^T @ dZ1 / batch    # (784, 512) Gradiente de W1
7. db1 = sum(dZ1) / batch     # (512,) Gradiente de b1
```

### Actualizaci√≥n de Pesos

```
W1 = W1 - Œ± * dW1   # Œ± = 0.01 (learning rate)
b1 = b1 - Œ± * db1
W2 = W2 - Œ± * dW2
b2 = b2 - Œ± * db2
```

### Cuello de Botella Computacional

**El 95% del tiempo est√° en la multiplicaci√≥n de matrices**:

- `X @ W1`: (batch, 784) √ó (784, 512) = **401,408 operaciones/imagen**
- `A1 @ W2`: (batch, 512) √ó (512, 10) = **5,120 operaciones/imagen**

**Por eso se paraleliza la multiplicaci√≥n de matrices**.

---

## ‚ö° PARALELIZACI√ìN (Tu contribuci√≥n principal)

### OpenMP: Estrategias Implementadas

#### 1. Paralelizaci√≥n de GEMM (General Matrix Multiply)

```c
// ANTES (Secuencial)
for (int i = 0; i < M; i++) {
    for (int j = 0; j < N; j++) {
        float sum = 0.0f;
        for (int k = 0; k < K; k++) {
            sum += A[i*K + k] * B[k*N + j];
        }
        C[i*N + j] = sum;
    }
}

// DESPU√âS (Paralelo)
#pragma omp parallel for collapse(2) schedule(dynamic)
for (int i = 0; i < M; i++) {
    for (int j = 0; j < N; j++) {
        float sum = 0.0f;
        for (int k = 0; k < K; k++) {
            sum += A[i*K + k] * B[k*N + j];
        }
        C[i*N + j] = sum;
    }
}
```

**Explicaci√≥n**:

- `collapse(2)`: Combina los 2 loops externos en uno solo (m√°s trabajo paralelo)
- `schedule(dynamic)`: Distribuye trabajo din√°micamente (mejor balanceo)

#### 2. Reducci√≥n Paralela para Gradientes

```c
#pragma omp parallel for reduction(+:db2[:OUTPUT_SIZE])
for (int i = 0; i < batch_size; i++) {
    for (int j = 0; j < OUTPUT_SIZE; j++) {
        db2[j] += gradients[i * OUTPUT_SIZE + j];
    }
}
```

**Explicaci√≥n**:

- `reduction(+:array)`: Cada hilo acumula en su copia privada, luego se suman

### Escalabilidad Medida

| Hilos | Tiempo (s) | Speedup   | Eficiencia |
| ----- | ---------- | --------- | ---------- |
| 1     | 1539       | 1.0√ó      | 100%       |
| 2     | 820        | 1.88√ó     | 94%        |
| 4     | 450        | 3.42√ó     | 86%        |
| 8     | 346        | **4.45√ó** | 56%        |

**Observaci√≥n**: La eficiencia baja al aumentar hilos (Ley de Amdahl).

---

## üß™ EXPERIMENTOS Y M√âTRICAS

### M√©tricas a Recopilar

Para cada implementaci√≥n, registra en `results/raw/<nombre>.csv`:

```csv
epoch,train_loss,train_accuracy,test_accuracy,time_seconds
1,0.532,0.842,0.838,154.3
2,0.321,0.906,0.901,152.1
...
```

### Gr√°ficas del Informe

#### 1. Speedup vs. N√∫mero de Hilos (OpenMP)

```
Speedup
   8√ó  ‚î§
   7√ó  ‚î§                           ‚ï± Ideal (lineal)
   6√ó  ‚î§                        ‚ï±
   5√ó  ‚î§                     ‚ï±
   4√ó  ‚î§                  ‚ï±‚Ä¢‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Real (4.45√ó)
   3√ó  ‚î§               ‚ï±‚Ä¢
   2√ó  ‚î§            ‚ï±‚Ä¢
   1√ó  ‚î§‚Ä¢‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Ä¢
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
       1  2  4  6  8  10  12  14  Hilos
```

**An√°lisis**: ¬øPor qu√© no es lineal? (Overhead, sincronizaci√≥n, Amdahl)

#### 2. Comparaci√≥n de Tiempos

```
Tiempo (segundos)
2000 ‚î§ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  Python Seq (1800s)
1500 ‚î§ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     C Seq (1539s)
1000 ‚î§ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             Python MP (900s)
 500 ‚î§ ‚ñà‚ñà‚ñà‚ñà                  C OpenMP (346s)
   0 ‚î§
```

#### 3. Profiling GPU (futuro)

```
Transfer CPU‚ÜíGPU:  15% (120ms)
Kernel Execution:  70% (560ms)
Transfer GPU‚ÜíCPU:  10% (80ms)
Overhead:           5% (40ms)
```

---

## üé§ GU√çA DE SUSTENTACI√ìN

### ¬øNecesitas Frontend/Backend?

**Para la sustentaci√≥n acad√©mica: NO ES OBLIGATORIO**

El proyecto requiere:

1. ‚úÖ **C√≥digo fuente** de las 6 implementaciones
2. ‚úÖ **Informe t√©cnico** con m√©tricas y an√°lisis
3. ‚úÖ **Presentaci√≥n oral** (10-15 min)

**El frontend es un EXTRA** que demuestra que el modelo funciona, pero puedes sustentar solo con:

- Terminal mostrando el entrenamiento
- CSVs con m√©tricas
- Gr√°ficas en el informe

### C√≥mo Usar Todo Manualmente (sin Frontend)

#### Escenario 1: Solo entrenar y ver m√©tricas

```bash
# 1. Entrenar modelo C Secuencial
cd backend/c_secuencial
make
./bin/train_seq.exe

# Ver√°s en consola:
# Epoch 1/10: Loss=0.532, Train Acc=84.2%, Test Acc=83.8% (154s)
# Epoch 2/10: Loss=0.321, Train Acc=90.6%, Test Acc=90.1% (152s)
# ...

# 2. Entrenar modelo C OpenMP (8 hilos)
cd ../c_openmp
make
set OMP_NUM_THREADS=8
./bin/train_openmp.exe

# 3. Ver resultados en CSV
cat backend/results/raw/c_sequential.csv
cat backend/results/raw/c_openmp.csv

# 4. Generar gr√°ficas con Python
cd backend/scripts
python plot_results.py  # (si tienes este script)
```

#### Escenario 2: Mostrar predicciones en vivo

**Opci√≥n A: Con Frontend (m√°s bonito)**

```bash
# Terminal 1: API
cd backend/api
npm start

# Terminal 2: Frontend
cd frontend
npm run dev

# Navegador: http://localhost:5173
# Dibujas un "7" ‚Üí Modelo predice "7 (95%)"
```

**Opci√≥n B: Sin Frontend (solo API + curl)**

```bash
# Terminal 1: API
cd backend/api
npm start

# Terminal 2: Probar predicci√≥n
curl -X POST http://localhost:3001/api/predict \
  -H "Content-Type: application/json" \
  -d '{
    "modelId": "openmp",
    "image": [0,0,0,...,255,...,0]  # Array de 784 valores (0-255)
  }'

# Respuesta:
# {"success":true,"prediction":7,"probabilities":[0.01,0.02,...,0.95,...]}
```

**Opci√≥n C: Solo l√≠nea de comandos (test.c)**

Crea un peque√±o programa que cargue los pesos y prediga una imagen:

```c
// test_prediction.c
#include "mlp.h"
#include "data.h"

int main() {
    MLP mlp;
    mlp_load_weights(&mlp, "model_weights_openmp.json");

    // Cargar imagen de prueba (por ej. la #0 del test set)
    float image[784];
    load_test_image(0, image);

    // Predecir
    float output[10];
    mlp_forward(&mlp, image, output);

    // Mostrar
    int predicted = argmax(output, 10);
    printf("Imagen #0: Predicci√≥n = %d (confianza: %.2f%%)\n",
           predicted, output[predicted]*100);
}
```

### Estructura de la Presentaci√≥n (10-15 min)

#### Diapositiva 1: Portada

- T√≠tulo del proyecto
- Nombres
- Fecha

#### Diapositiva 2: Contexto

- ¬øPor qu√© Deep Learning es costoso?
- Necesidad de paralelizaci√≥n
- Objetivo: Comparar paradigmas

#### Diapositiva 3: Arquitectura MLP

- Diagrama de 3 capas
- Ecuaciones Forward/Backward
- Cuello de botella: GEMM

#### Diapositiva 4: Implementaciones

- Tabla con las 6 versiones
- Estado actual (4/6 completadas)

#### Diapositiva 5: Metodolog√≠a

- Hardware usado (CPU, RAM, n√∫cleos)
- Hiperpar√°metros fijos
- C√≥mo se midi√≥ el tiempo

#### Diapositiva 6: Resultados - Tabla Comparativa

```
| Versi√≥n           | Tiempo | Speedup | Accuracy |
|-------------------|--------|---------|----------|
| Python Seq        | 1800s  | 1.0√ó    | 93.2%    |
| C Seq             | 1539s  | 1.17√ó   | 93.5%    |
| Python MP (4 proc)| 900s   | 2.0√ó    | 93.2%    |
| C OpenMP (8 hilos)| 346s   | 5.2√ó    | 93.5%    |
```

#### Diapositiva 7: Gr√°fica Speedup OpenMP

- Curva Real vs. Ideal
- An√°lisis de Amdahl

#### Diapositiva 8: Demo en Vivo (opcional)

- Mostrar frontend prediciendo un d√≠gito
- O ejecutar en terminal

#### Diapositiva 9: Conclusiones

- OpenMP logr√≥ 4.45√ó con 8 hilos
- Multiprocessing tiene overhead de IPC
- GPU (futuro) promete 10-50√ó

#### Diapositiva 10: Preguntas

---

## üõ†Ô∏è C√ìMO CORRER TODO PASO A PASO

### Pre-requisitos

**Windows (MSYS2)**:

```bash
# Ya debes tener instalado (seg√∫n INSTALL_C_TOOLS.md):
- GCC con OpenMP
- Make
- Node.js + npm
- Python 3.8+
```

### Paso 1: Descargar y preprocesar MNIST

```bash
cd backend/scripts
python download_mnist.py
python preprocess_for_c.py

# Verifica:
ls backend/data/mnist/
# Deber√≠as ver: train_images.bin, train_labels.bin, etc.
```

### Paso 2: Entrenar modelos C

```bash
# Secuencial
cd backend/c_secuencial
make clean
make
./bin/train_seq.exe  # Toma ~25 min

# OpenMP (8 hilos)
cd ../c_openmp
make clean
make
set OMP_NUM_THREADS=8
./bin/train_openmp.exe  # Toma ~6 min
```

### Paso 3: Verificar exportaci√≥n de pesos

```bash
# Deben existir:
ls backend/api/model_weights_sequential.json
ls backend/api/model_weights_openmp.json
```

### Paso 4: Levantar el stack completo

```bash
# Terminal 1: API
cd backend/api
npm install
npm start  # Puerto 3001

# Terminal 2: Frontend
cd frontend
npm install
npm run dev  # Puerto 5173

# Navegador:
# http://localhost:5173
```

### Paso 5: Probar predicci√≥n

1. Dibuja un d√≠gito (ej. "5")
2. Selecciona modelo ("C OpenMP")
3. Click "Predecir"
4. Ver√°s: "Predicci√≥n: 5 (Confianza: 92%)"

---

## üî¨ AN√ÅLISIS PROFUNDO

### ¬øPor qu√© C es m√°s r√°pido que Python?

1. **Compilado vs. Interpretado**: C se compila a c√≥digo m√°quina nativo
2. **Sin GIL**: Python tiene el Global Interpreter Lock
3. **Control de memoria**: C gestiona memoria manualmente (malloc/free)
4. **Optimizaciones del compilador**: `-O3` aplica vectorizaci√≥n, loop unrolling

### ¬øPor qu√© OpenMP escala bien?

1. **Memoria compartida**: Los hilos comparten W1, W2 (no hay copia)
2. **Granularidad gruesa**: Cada hilo procesa m√∫ltiples filas de la matriz
3. **Buen locality**: Accesos a memoria son secuenciales (cache-friendly)

### ¬øQu√© limita el Speedup? (Ley de Amdahl)

```
Speedup = 1 / (S + P/N)

S = Fracci√≥n secuencial (ej. 0.05 = 5%)
P = Fracci√≥n paralelizable (ej. 0.95 = 95%)
N = N√∫mero de hilos

Ejemplo con 8 hilos:
Speedup = 1 / (0.05 + 0.95/8) = 1 / 0.169 = 5.92√ó

Real: 4.45√ó (porque overhead de sincronizaci√≥n)
```

**Partes secuenciales**:

- Carga de datos
- Escritura de logs
- Actualizaci√≥n de pesos (tiene secci√≥n cr√≠tica)

---

## üìù CHECKLIST DE ENTREGA

### C√≥digo Fuente ‚úÖ

```
‚úÖ c_secuencial/     (compilable con make)
‚úÖ c_openmp/         (compilable con make)
‚è≥ pycuda_gpu/       (pendiente)
‚úÖ py_secuencial/    (en rama devS)
‚úÖ py_multiprocessing/ (en rama devS)
‚úÖ frontend/         (extra, no requerido)
‚úÖ backend/api/      (extra, no requerido)
```

### Informe T√©cnico (Word/PDF)

```
[ ] 1. Introducci√≥n (contexto, objetivos)
[ ] 2. Arquitectura MLP (diagrama, ecuaciones)
[ ] 3. Metodolog√≠a (hardware, hiperpar√°metros)
[ ] 4. Resultados:
    [ ] 4.1 Tabla comparativa de tiempos
    [ ] 4.2 Gr√°fica Speedup OpenMP
    [ ] 4.3 An√°lisis Ley de Amdahl
    [ ] 4.4 Comparaci√≥n Python MP vs. C OpenMP
    [ ] 4.5 Profiling GPU (si completan CUDA)
[ ] 5. Conclusiones
[ ] 6. Referencias
```

### Presentaci√≥n (PPT/PDF)

```
[ ] 10-12 diapositivas
[ ] M√°ximo 15 minutos
[ ] Todos los miembros participan
[ ] Incluir gr√°ficas del informe
```

---

## üö® PROBLEMAS COMUNES

### 1. "No se encuentran archivos .bin"

**Soluci√≥n**:

```bash
cd backend/scripts
python preprocess_for_c.py
```

### 2. "OpenMP no compila"

**Soluci√≥n**:

```bash
# Verifica que gcc soporte OpenMP:
gcc -fopenmp --version

# Si no, reinstala gcc con MSYS2:
pacman -S mingw-w64-x86_64-gcc
```

### 3. "Frontend no se conecta a la API"

**Soluci√≥n**:

```bash
# Verifica que la API est√© corriendo:
curl http://localhost:3001/api/health

# Si no responde, revisa que:
# 1. npm start est√© corriendo en backend/api
# 2. No haya otro proceso en puerto 3001
```

### 4. "Accuracy es muy bajo (<80%)"

**Causas**:

- Pesos inicializados incorrectamente
- Learning rate muy alto/bajo
- Bug en backpropagation

**Debug**:

```bash
# Compara pesos de √©poca 1 con implementaci√≥n conocida
# Verifica que la loss disminuya cada √©poca
```

---

## üéØ PR√ìXIMOS PASOS

### Inmediato (antes de sustentar)

1. ‚úÖ Commitear y pushear rama `dev`
2. ‚úÖ Integrar c√≥digo Python de `devS`
3. ‚è≥ Completar informe t√©cnico
4. ‚è≥ Crear presentaci√≥n
5. ‚è≥ Ensayar sustentaci√≥n

### Opcional (si hay tiempo)

6. ‚è≥ Implementar CUDA/PyCUDA
7. ‚è≥ Mejorar visualizaciones del frontend
8. ‚è≥ Agregar m√°s gr√°ficas al informe

---

## üìö RECURSOS

### Documentaci√≥n Interna

- `backend/docs/FORMULAS_IMPLEMENTACION.md`: Matem√°ticas detalladas
- `backend/docs/WORKFLOW.md`: Dependencias entre componentes
- `backend/docs/INSTALL_C_TOOLS.md`: Setup de herramientas

### Referencias Externas

- MNIST Dataset: http://yann.lecun.com/exdb/mnist/
- OpenMP Tutorial: https://computing.llnl.gov/tutorials/openMP/
- Backpropagation: http://neuralnetworksanddeeplearning.com/

---

## üí° TIPS PARA LA SUSTENTACI√ìN

### 1. Demuestra que entiendes TODO

**Pregunta t√≠pica**: "¬øPor qu√© ReLU en lugar de sigmoid?"

**Respuesta**:

> "ReLU evita el problema de vanishing gradient porque su derivada es siempre 1 (si x>0) o 0 (si x‚â§0). Sigmoid satura en los extremos, haciendo que la derivada sea casi cero y el aprendizaje se detenga."

### 2. S√© honesto sobre limitaciones

**Pregunta**: "¬øPor qu√© solo lograron 4.45√ó con 8 hilos?"

**Respuesta**:

> "Seg√∫n la Ley de Amdahl, el speedup te√≥rico m√°ximo es 1/(S + P/N). Estimamos que el 5% del c√≥digo es secuencial (carga de datos, logs). Adem√°s, hay overhead de sincronizaci√≥n en las secciones cr√≠ticas (actualizaci√≥n de pesos). Por eso no logramos el ideal de 8√ó."

### 3. Relaciona con el mundo real

**Pregunta**: "¬øC√≥mo se relaciona esto con frameworks como TensorFlow?"

**Respuesta**:

> "TensorFlow usa GEMM (multiplicaci√≥n de matrices) implementado en cuBLAS (GPU) o MKL (CPU). Nosotros implementamos GEMM desde cero para entender los cuellos de botella. En producci√≥n, siempre usar√≠amos librer√≠as optimizadas."

### 4. Demuestra el frontend (si lo tienes)

- Es visual y impresionante
- Muestra que el modelo REALMENTE funciona
- Diferencia tu proyecto del de otros grupos

### 5. Ten m√©tricas a la mano

- Speedup exacto (4.45√ó)
- Tiempo por √©poca (346s vs. 1539s)
- Accuracy final (93.5%)

---

## ‚úÖ CONCLUSI√ìN

**Lo que YA TIENES (rama `dev`)**:

- ‚úÖ C Secuencial (completo y funcional)
- ‚úÖ C OpenMP (4.45√ó speedup)
- ‚úÖ Frontend React (extra, no obligatorio)
- ‚úÖ API Node.js (extra, no obligatorio)
- ‚úÖ Sistema de exportaci√≥n de pesos

**Lo que FALTA (rama `devS` de tu compa√±ero)**:

- Python Secuencial
- Python Multiprocessing

**Lo que QUEDA POR HACER (ambos)**:

- CUDA/PyCUDA
- Informe t√©cnico
- Presentaci√≥n

**Para sustentar SOLO TU PARTE**:

1. Demuestra entrenamiento en C (secuencial y OpenMP)
2. Muestra gr√°fica de Speedup
3. Explica optimizaciones con OpenMP
4. (Opcional) Demo del frontend

**Tiempo estimado para preparar sustentaci√≥n**: 2-3 d√≠as

---

**¬øPreguntas? Revisa esta gu√≠a o consulta los archivos en `backend/docs/`**
